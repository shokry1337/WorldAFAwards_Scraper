import asyncio, saveload
from datetime import timedelta
from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext
from playwright.sync_api import TimeoutError as PlaywrightTimeoutError

ids = []

async def get_text(ctx, selector):
    loc = ctx.page.locator(f'.modal.show {selector}')
    try:
        await loc.wait_for(state='visible', timeout=2000)
        return (await loc.inner_text()).strip() if await loc.count() else ''
    except PlaywrightTimeoutError:
        print(f"‚ö†Ô∏è Couldn't find '{selector}' or it's not visible on screen. Moving on! ")
        return ''
    except Exception as e:
        print(f"‚ùå Ran into a snag trying to get text from '{selector}': {e}. ")
        return ''

async def handle(ctx: PlaywrightCrawlingContext):
    print(f"üåê We've landed on: {ctx.page.url}")

    cookie_modal_selector = '#cookieConsent.modal.show'
    accept_button_selector = '#cookieConsent .accept-policy'

    try:
        await ctx.page.wait_for_selector(cookie_modal_selector, timeout=10000)
        print('üç™ A cookie consent pop-up just appeared! ')

        accept_button = ctx.page.locator(accept_button_selector)
        await accept_button.click()
        print('‚úÖ We clicked to accept the cookies. ')

        await ctx.page.wait_for_selector(cookie_modal_selector, state='hidden', timeout=5000)
        print('üëç Cookie consent pop-up is now out of sight, out of mind! ')

    except PlaywrightTimeoutError:
        print('üòå No cookie consent pop-up found, or it vanished super fast. All clear! ')
    except Exception as e:
        print(f'üö® Something unexpected happened with the cookie consent pop-up: {e}. ')

    print('üöÄ Kicking off the scraping process now... ')
    await ctx.page.wait_for_selector('a[data-bs-toggle="modal"]')

    links = await ctx.page.locator('a[data-bs-toggle="modal"]').all()
    print(f'üîç Found {len(links)} items on the page to explore! ')

    for i, link in enumerate(links):
        
        item_id = await link.get_attribute("data-id")
        if not item_id:
            print(f"‚ö†Ô∏è Item {i+1} seems to be missing its ID. Skipping this one for now. ")
            continue

        if item_id in ids:
            print(f"‚è© Already processed item {i + 1} ({item_id}). Skipping to the next! ")
            await ctx.page.wait_for_timeout(700)
            continue

        ids.append(item_id) 
        
        print(f'‚ú® Diving into item {i + 1}/{len(links)} ({item_id})... ')

        try:
            await link.scroll_into_view_if_needed()
            await link.wait_for(state='visible', timeout=5000)
            await link.click()
            print('üëâ Link clicked successfully! ')
        except PlaywrightTimeoutError:
            print(f"‚è∞ Timeout trying to click item {i+1} ({item_id}). It just wouldn't show up! ")
            continue
        except Exception as e:
            print(f"üí• Encountered an error clicking item {i+1} ({item_id}): {e}. ")
            continue

        try:
            await ctx.page.wait_for_selector(".modal.show", timeout=10000)
            print(f"‚úîÔ∏è The modal for item {i+1} ({item_id}) has appeared. ")

            website_href = ""
            website_locator = ctx.page.locator('.modal.show #website a')
            try:
                await website_locator.wait_for(state='attached', timeout=3000) 
                website_href = await website_locator.get_attribute("href") or ""
            except PlaywrightTimeoutError:
                print(f"üîó Couldn't find the website link for item '{item_id}' or it took too long to load. No worries! ")
            except Exception as e:
                print(f"‚ùå Something unexpected happened while grabbing the website for item {i+1} ({item_id}): {e}. ")

            data = {
                "ID": item_id, 
                "Brand": await get_text(ctx, "#brandName"),
                "Product": await get_text(ctx, "#productName"),
                "Producer": await get_text(ctx, "#producerName"),
                "Country": await get_text(ctx, "#countryName"),
                "ABV": str(await get_text(ctx, "#abv")).replace("ABV ", ""),
                "Note": str(await get_text(ctx, "#note")).replace("JUDGES' TASTING NOTE\n", ""),
                "Categories": await get_text(ctx, "#categories"),
                "Energy": str(await get_text(ctx, "#energy")).replace("Energy: ", ""), 
                "Carbs": str(await get_text(ctx, "#carbs")).replace("Carbohydrates: ", ""),
                "Sugars": str(await get_text(ctx, "#sugars")).replace("Sugars: ", ""),
                "Website": website_href
            }

            saveload.append(data)
            print(f"üíæ Data for item {i+1} ({item_id}) saved! ")

        except Exception as e:
            print(f"üêõ Ran into an issue while extracting data for item {i+1} ({item_id}): {e}. ")

        finally:
            try:
                close_button = ctx.page.locator(".modal.show .btn-close").first
                await close_button.wait_for(state='visible', timeout=2000)
                await close_button.click()
                await ctx.page.wait_for_selector(".modal.show", state='hidden', timeout=5000)
                print(f"‚úñÔ∏è Modal for item {i+1} ({item_id}) closed successfully! ")
            except PlaywrightTimeoutError:
                print(f"ü§∑‚Äç‚ôÄÔ∏è Couldn't find the close button or the modal for item {i+1} ({item_id}) just wouldn't close. Trying 'Escape'! ")
                await ctx.page.keyboard.press('Escape')
                await ctx.page.wait_for_timeout(500)
            except Exception as e:
                print(f"üö´ Unexpected problem closing the modal for item {i+1} ({item_id}): {e}. ")

            await ctx.page.wait_for_timeout(1000)


async def run():
    global ids
    ids = saveload.init()
    print('üìÇ Loaded existing IDs. Ready to roll! ')

    crawler = PlaywrightCrawler(
        headless=True,
        request_handler_timeout=timedelta(seconds=900)
    )
    crawler.router.default_handler(handle)
    await crawler.add_requests(['https://worldafawards.com/results/2025'])
    await crawler.run()
    print('üéâ All done!')

if __name__ == '__main__':
    asyncio.run(run())
